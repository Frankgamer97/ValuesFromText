{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e67dcff7-f285-4132-8ea8-65824d19e440",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrittura_file(df, path, nome_file, header):\n",
    "    if not os.path.isfile(nome_file):\n",
    "        df.to_csv(nome_file, index=False, header=header)\n",
    "    else:\n",
    "        df.to_csv(nome_file, mode='a', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a024a622-f584-4abf-82e6-15ed8b286650",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: rdflib in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (6.1.1)\n",
      "Requirement already satisfied: isodate in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from rdflib) (0.6.1)\n",
      "Requirement already satisfied: setuptools in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from rdflib) (58.1.0)\n",
      "Requirement already satisfied: pyparsing in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from rdflib) (3.0.7)\n",
      "Requirement already satisfied: six in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from isodate->rdflib) (1.16.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.3.1; however, version 22.1.2 is available.\n",
      "You should consider upgrading via the '/Library/Frameworks/Python.framework/Versions/3.9/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: SPARQLWrapper in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (1.8.5)\n",
      "Requirement already satisfied: rdflib>=4.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from SPARQLWrapper) (6.1.1)\n",
      "Requirement already satisfied: pyparsing in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from rdflib>=4.0->SPARQLWrapper) (3.0.7)\n",
      "Requirement already satisfied: isodate in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from rdflib>=4.0->SPARQLWrapper) (0.6.1)\n",
      "Requirement already satisfied: setuptools in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from rdflib>=4.0->SPARQLWrapper) (58.1.0)\n",
      "Requirement already satisfied: six in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from isodate->rdflib>=4.0->SPARQLWrapper) (1.16.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.3.1; however, version 22.1.2 is available.\n",
      "You should consider upgrading via the '/Library/Frameworks/Python.framework/Versions/3.9/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install rdflib\n",
    "!pip install SPARQLWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0c8ad43b-9395-4b6d-bbd9-e5eb4e61eaae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "import requests\n",
    "import rdflib\n",
    "from rdflib import Graph, Literal, RDF, URIRef, Namespace, BNode\n",
    "import SPARQLWrapper\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON, N3, TURTLE, RDF, CSV\n",
    "import json\n",
    "import os\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "import openpyxl\n",
    "from openpyxl import Workbook\n",
    "from openpyxl import load_workbook\n",
    "\n",
    "\n",
    "\n",
    "headers = {\n",
    "    'accept': 'text/turtle',\n",
    "    'Authorization': 'Bearer a7727b8c-aa1e-39d4-8b34-3977ec1c73f5',\n",
    "}\n",
    "\n",
    "# here you declare the endpoint, you can have it in localhost or you can use the online Framester one\n",
    "\n",
    "valuesparql = SPARQLWrapper('http://localhost:3030/ValueNet/sparql') # change with: 'http://etna.istc.cnr.it/framester2/sparql'\n",
    "\n",
    "\n",
    "\n",
    "comment = URIRef(\"http://www.w3.org/2000/01/rdf-schema#comment\")\n",
    "sample_phrase = URIRef(\"http://sample_phrase.org/\")\n",
    "\n",
    "\n",
    "\n",
    "all_names = [Namespace(\"https://w3id.org/framester/wn/wn30/\"), Namespace(\"https://w3id.org/framester/vn/vn31/data/\"), Namespace(\"<http://dbpedia.org/resource/\"), Namespace(\"https://w3id.org/framester/data/framestercore/\"), Namespace(\"https://w3id.org/framester/pb/pbdata/\"), Namespace(\"https://w3id.org/framester/framenet/abox/gfe/\"), Namespace(\"https://w3id.org/framester/pb/pbschema/\"), Namespace(\"https://w3id.org/framester/wn/wn30/wordnet-verbnountropes/\"), Namespace(\"https://w3id.org/framester/data/framesterrole/\"), Namespace(\"http://babelnet.org/rdf/\"), Namespace(\"https://w3id.org/framester/framenet/abox/fe/\"), Namespace(\"https://w3id.org/framester/framenet/abox/frame/\"), Namespace(\"https://w3id.org/framester/data/framestersyn/\") ]\n",
    "\n",
    "\n",
    "\n",
    "# this function makes a call to FRED to generate a graph from sentence (you can save it as Turtle file .ttl)\n",
    "\n",
    "def test_graph(txt):\n",
    "  params = (\n",
    "      ('text', txt), #cv),\n",
    "      ('wfd_profile', 'b'),\n",
    "      ('textannotation', 'earmark'),\n",
    "      ('wfd', True),\n",
    "      ('roles', False),\n",
    "      ('alignToFramester', True),\n",
    "      ('semantic-subgraph', True)\n",
    "  )\n",
    "  response = requests.get('http://wit.istc.cnr.it/stlab-tools/fred', headers=headers, params=params)\n",
    "  #return response.text \n",
    "  with open('out1.ttl','w') as out1: \n",
    "    out1.write(response.text)\n",
    "\n",
    "\n",
    "# this function find value triggers\n",
    "\n",
    "def find_trigs(input,txt):    \n",
    "    \n",
    "# generate graphs to be used later \n",
    "\n",
    "  g_valueObj = rdflib.Graph()\n",
    "  g_valueSubj = rdflib.Graph()\n",
    "\n",
    "  g = rdflib.Graph()\n",
    "  finalg = rdflib.Graph()\n",
    "  cell_graph = g.parse(input, format=\"ttl\")\n",
    "\n",
    "  # create list of subject and objects of triples to store entities URIs in order to iterate on them\n",
    "\n",
    "  sub = []\n",
    "  obj = []\n",
    "  for s,p,o in cell_graph:\n",
    "        \n",
    "        # URIs generated in FRED graph could be different from those in Framester, therefore the replacement\n",
    "\n",
    "        s = str(s).replace(\"http://www.w3.org/2006/03/wn/wn30/instances\", \"https://w3id.org/framester/wn/wn30/instances\")\n",
    "        o = str(o).replace(\"http://www.w3.org/2006/03/wn/wn30/instances\", \"https://w3id.org/framester/wn/wn30/instances\")\n",
    "        s = str(s).replace(\"http://www.ontologydesignpatterns.org/ont/vn/data\", \"https://w3id.org/framester/vn/vn31/data\")\n",
    "        o = str(o).replace(\"http://www.ontologydesignpatterns.org/ont/vn/data\", \"https://w3id.org/framester/vn/vn31/data\")\n",
    "        \n",
    "        for k in all_names:\n",
    "            if k in s:\n",
    "                vs_list = []\n",
    "                vs_list.append(s)\n",
    "                \n",
    "                for z in vs_list:\n",
    "                    \n",
    "                    # query to retrieve all subjects of triples which trigger some value in ValueNet\n",
    "                    \n",
    "                    queryValueSubj = (\n",
    "                    '''\n",
    "                    PREFIX vcvf: <http://www.ontologydesignpatterns.org/ont/values/valuecore_with_value_frames.owl#>\n",
    "                    PREFIX haidt: <https://w3id.org/spice/SON/HaidtValues#>\n",
    "\n",
    "                    CONSTRUCT { <'''+z+'''> vcvf:triggers ?o . }\n",
    "                    WHERE\n",
    "                      { <'''+z+'''> vcvf:triggers ?o . }\n",
    "                    '''\n",
    "                    )\n",
    "                    \n",
    "                    # store the triple in a graph\n",
    "                    \n",
    "                    valuesparql.setQuery(queryValueSubj)\n",
    "                    valuesparql.setReturnFormat(TURTLE)\n",
    "                    resultsValueSubj = valuesparql.query().convert()\n",
    "                    g_valueSubj = g_valueSubj.parse(resultsValueSubj, format=\"ttl\")\n",
    "                    \n",
    "                    \n",
    "\n",
    "            if k in o:\n",
    "                vo_list = []\n",
    "                vo_list.append(o)\n",
    "                for q in vo_list:\n",
    "                    \n",
    "                    # query to retrieve all objects of triples which trigger some value in ValueNet\n",
    "\n",
    "                    \n",
    "                    queryValueObj = (\n",
    "                    '''\n",
    "                    PREFIX vcvf: <http://www.ontologydesignpatterns.org/ont/values/valuecore_with_value_frames.owl#>\n",
    "                    PREFIX haidt: <https://w3id.org/spice/SON/HaidtValues#>\n",
    "\n",
    "                    CONSTRUCT { <'''+o+'''> vcvf:triggers ?o . }\n",
    "                    WHERE\n",
    "                    { <'''+o+'''> vcvf:triggers ?o . }\n",
    "                    '''\n",
    "                    )\n",
    "\n",
    "                    # store the triple in a graph\n",
    "                    \n",
    "                    valuesparql.setQuery(queryValueObj)\n",
    "                    valuesparql.setReturnFormat(TURTLE)\n",
    "                    resultsValueObj = valuesparql.query().convert()\n",
    "                    g_valueObj = g_valueObj.parse(resultsValueObj, format=\"ttl\")\n",
    "                    \n",
    "                    \n",
    "               \n",
    "                    \n",
    "        # merge all graphs in a new graph\n",
    "                \n",
    "        finalg = cell_graph + g_valueSubj + g_valueObj \n",
    "        \n",
    "\n",
    "        sub += [s for s,p,o in finalg if 'triggers' in p]\n",
    "        obj += [o for s,p,o in finalg if 'triggers' in p]\n",
    "        \n",
    "#  for s,p,o in finalg:\n",
    "#    print(s,p,o)\n",
    "\n",
    "     \n",
    "\n",
    "  diz = {'sub':sub,\n",
    "         'obj':obj}  \n",
    "  return diz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "066c78e1-73b8-450e-a449-f14153cb7a1c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sklearn in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (0.0)\n",
      "Requirement already satisfied: scikit-learn in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from sklearn) (1.0.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from scikit-learn->sklearn) (3.1.0)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from scikit-learn->sklearn) (1.8.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from scikit-learn->sklearn) (1.1.0)\n",
      "Requirement already satisfied: numpy>=1.14.6 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from scikit-learn->sklearn) (1.22.1)\n",
      "\u001b[33mWARNING: You are using pip version 21.3.1; however, version 22.1.2 is available.\n",
      "You should consider upgrading via the '/Library/Frameworks/Python.framework/Versions/3.9/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40334222-2481-4d67-b241-45dd048690cc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['harm']\n",
      "{'sent': ['Someone has to stop that awful killer'], 'label': [nan], 'pred': ['harm'], 'trig': ['https://w3id.org/framester/data/framestercore/Killing, https://w3id.org/framester/wn/wn30/instances/synset-killer-noun-1']}\n",
      "0/1\n"
     ]
    }
   ],
   "source": [
    "from urllib.error import HTTPError\n",
    "\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "t = 20\n",
    "\n",
    "# here you declare the path to your file to be tested\n",
    "\n",
    "doc = pd.read_csv('/Users/sdg/Downloads/DMH_value_test1 - Foglio6.csv')\n",
    "\n",
    "for index,row in doc.iterrows():\n",
    "  txt = row['txt']\n",
    "  label = row['label']\n",
    "  try:\n",
    "    out1 = test_graph(txt)\n",
    "    out2 = find_trigs('out1.ttl',txt)\n",
    "\n",
    "    # this is just to have a cleaner output without the full URI but only with the value name\n",
    "    \n",
    "    predizione = [ele.replace('https://w3id.org/spice/SON/HaidtValues#','').strip().lower() for ele in list(set([str(ele) for ele in out2['obj']]))]\n",
    "\n",
    "    print(predizione)\n",
    "\n",
    "    # in \"label\" you can put e.g. \"loyalty-betrayal\" from social chemistry file\n",
    "    \n",
    "    out = {'sent':[txt],\n",
    "        'label':[label],\n",
    "        'pred':[', '.join(predizione)],\n",
    "        'trig':[', '.join(list(set([str(ele) for ele in out2['sub']])))]}\n",
    "    print(out)\n",
    "\n",
    "    df = pd.DataFrame(out)\n",
    "    scrittura_file (df, '', 'emoval_DMH_foglio6.csv', [k for k in out.keys()])\n",
    "    #if index==1:break\n",
    "\n",
    "    print(f\"{index}/{len(doc)}\")\n",
    "\n",
    "    if (requests.exceptions.HTTPError, requests.exceptions.ConnectionError, requests.exceptions.Timeout):\n",
    "      time.sleep(t)\n",
    "\n",
    "  except Exception:\n",
    "    continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6b4e2f59-ffa0-4c52-b454-9edb61ed64e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        care       0.28      0.58      0.38       439\n",
      "      purity       0.24      0.45      0.31       139\n",
      "   non-moral       0.64      0.65      0.65      2553\n",
      "     loyalty       0.32      0.27      0.29       336\n",
      "    cheating       0.73      0.32      0.44       571\n",
      "    fairness       0.26      0.25      0.25       374\n",
      "  subversion       0.28      0.17      0.21       347\n",
      "    betrayal       0.49      0.23      0.31       201\n",
      " degradation       0.45      0.10      0.17       247\n",
      "        harm       0.38      0.72      0.50       676\n",
      "   authority       0.16      0.14      0.15       276\n",
      "\n",
      "   micro avg       0.46      0.49      0.47      6159\n",
      "   macro avg       0.38      0.35      0.33      6159\n",
      "weighted avg       0.49      0.49      0.46      6159\n",
      " samples avg       0.49      0.51      0.49      6159\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#metriche \n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn import metrics, model_selection, preprocessing\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "# this is eventually to test some metrics, to be fine tuned according to your needs\n",
    "\n",
    "doc = pd.read_csv('emoval_DMH_foglio6.csv')\n",
    "\n",
    "mapping = {\n",
    "  0: 'care',\n",
    "  1: 'purity',\n",
    "  2: 'non-moral',\n",
    "  3: 'loyalty',\n",
    "  4: 'cheating',\n",
    "  5: 'fairness',\n",
    "  6: 'subversion',  \n",
    "  7: 'betrayal',\n",
    "  8: 'degradation',\n",
    "  9: 'harm',\n",
    "  10: 'authority'}\n",
    "\n",
    "label =  [[k for c in ele.split(',') for k,v in mapping.items() if c.strip() == v] for ele in doc['label']]\n",
    "predizioni = [[k for c in str(ele).split(',') for k,v in mapping.items() if c.strip() == v] for ele in doc['pred']]\n",
    "\n",
    "def one_hot (etichette):\n",
    "  out = []\n",
    "  for ele in etichette:\n",
    "    out_ = [0]*len(mapping)\n",
    "    for num in ele:\n",
    "      out_[num]=1\n",
    "    out+=[out_]\n",
    "  return out\n",
    "\n",
    "label = one_hot(label)\n",
    "predizioni = one_hot(predizioni)\n",
    "\n",
    "\n",
    "\n",
    "print(metrics.classification_report(label, predizioni, digits=2 , target_names = [v for v in mapping.values()]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cfdd53e-0dbc-49b8-9670-f5cd04677a72",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
