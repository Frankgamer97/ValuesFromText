{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e67dcff7-f285-4132-8ea8-65824d19e440",
   "metadata": {
    "id": "e67dcff7-f285-4132-8ea8-65824d19e440"
   },
   "outputs": [],
   "source": [
    "def scrittura_file(df, path, nome_file, header):\n",
    "    if not os.path.isfile(nome_file):\n",
    "        df.to_csv(nome_file, index=False, header=header)\n",
    "    else:\n",
    "        df.to_csv(nome_file, mode='a', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c8ad43b-9395-4b6d-bbd9-e5eb4e61eaae",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "0c8ad43b-9395-4b6d-bbd9-e5eb4e61eaae",
    "outputId": "d15e04b2-37ee-49a9-9436-e1d887043cf4",
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "import requests\n",
    "import rdflib\n",
    "from rdflib import Graph, Literal, RDF, URIRef, Namespace, BNode\n",
    "import SPARQLWrapper\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON, N3, TURTLE, RDF, CSV\n",
    "import json\n",
    "import os\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "import openpyxl\n",
    "from openpyxl import Workbook\n",
    "from openpyxl import load_workbook\n",
    "\n",
    "headers = {\n",
    "    'accept': 'text/turtle',\n",
    "    'Authorization': 'Bearer ef127c72-fa55-3075-9729-7263d0ae50d2',\n",
    "}\n",
    "\n",
    "# here you declare the endpoint, you can have it in localhost or you can use the online Framester one\n",
    "\n",
    "# valuesparql = SPARQLWrapper('http://localhost:3030/ValueNet/sparql') # change with: 'http://etna.istc.cnr.it/framester2/sparql'\n",
    "valuesparql = SPARQLWrapper('http://localhost:3030/ValueNet/sparql') # change with: 'http://etna.istc.cnr.it/framester2/sparql'\n",
    "\n",
    "comment = URIRef(\"http://www.w3.org/2000/01/rdf-schema#comment\")\n",
    "sample_phrase = URIRef(\"http://sample_phrase.org/\")\n",
    "\n",
    "all_names = [\n",
    "    Namespace(\"https://w3id.org/framester/wn/wn30/\"), \n",
    "    Namespace(\"https://w3id.org/framester/vn/vn31/data/\"), \n",
    "    Namespace(\"<http://dbpedia.org/resource/\"), \n",
    "    Namespace(\"https://w3id.org/framester/data/framestercore/\"), \n",
    "    Namespace(\"https://w3id.org/framester/pb/pbdata/\"), \n",
    "    Namespace(\"https://w3id.org/framester/framenet/abox/gfe/\"), \n",
    "    Namespace(\"https://w3id.org/framester/pb/pbschema/\"), \n",
    "    Namespace(\"https://w3id.org/framester/wn/wn30/wordnet-verbnountropes/\"), \n",
    "    Namespace(\"https://w3id.org/framester/data/framesterrole/\"), \n",
    "    Namespace(\"http://babelnet.org/rdf/\"), \n",
    "    Namespace(\"https://w3id.org/framester/framenet/abox/fe/\"), \n",
    "    Namespace(\"https://w3id.org/framester/framenet/abox/frame/\"), \n",
    "    Namespace(\"https://w3id.org/framester/data/framestersyn/\") \n",
    "]\n",
    "\n",
    "# this function makes a call to FRED to generate a graph from sentence (you can save it as Turtle file .ttl)\n",
    "\n",
    "def test_graph(txt):\n",
    "  params = (\n",
    "      ('text', txt), #cv),\n",
    "      ('wfd_profile', 'b'),\n",
    "      ('textannotation', 'earmark'),\n",
    "      ('wfd', True),\n",
    "      ('roles', False),\n",
    "      ('alignToFramester', True),\n",
    "      ('semantic-subgraph', True)\n",
    "  )\n",
    "  response = requests.get('http://wit.istc.cnr.it/stlab-tools/fred', headers=headers, params=params)\n",
    "  #return response.text \n",
    "  with open('out1.ttl','w') as out1: \n",
    "    out1.write(response.text)\n",
    "\n",
    "# this function find value triggers\n",
    "\n",
    "def find_trigs(input,txt):    \n",
    "    \n",
    "# generate graphs to be used later \n",
    "\n",
    "  g_valueObj = rdflib.Graph()\n",
    "  g_valueSubj = rdflib.Graph()\n",
    "\n",
    "  g = rdflib.Graph()\n",
    "  finalg = rdflib.Graph()\n",
    "  cell_graph = g.parse(input, format=\"ttl\")\n",
    "\n",
    "  # create list of subject and objects of triples to store entities URIs in order to iterate on them\n",
    "\n",
    "  sub = []\n",
    "  obj = []\n",
    "  for s,p,o in cell_graph:\n",
    "        \n",
    "        # URIs generated in FRED graph could be different from those in Framester, therefore the replacement\n",
    "\n",
    "        s = str(s).replace(\"http://www.w3.org/2006/03/wn/wn30/instances\", \"https://w3id.org/framester/wn/wn30/instances\")\n",
    "        o = str(o).replace(\"http://www.w3.org/2006/03/wn/wn30/instances\", \"https://w3id.org/framester/wn/wn30/instances\")\n",
    "        s = str(s).replace(\"http://www.ontologydesignpatterns.org/ont/vn/data\", \"https://w3id.org/framester/vn/vn31/data\")\n",
    "        o = str(o).replace(\"http://www.ontologydesignpatterns.org/ont/vn/data\", \"https://w3id.org/framester/vn/vn31/data\")\n",
    "        \n",
    "        for k in all_names:\n",
    "            if k in s:\n",
    "                vs_list = []\n",
    "                vs_list.append(s)\n",
    "                \n",
    "                for z in vs_list:\n",
    "                    \n",
    "                    # query to retrieve all subjects of triples which trigger some value in ValueNet\n",
    "                    \n",
    "                    queryValueSubj = (\n",
    "                    '''\n",
    "                    PREFIX vcvf: <http://www.semanticweb.org/sdg/ontologies/2022/0/valuecore_with_value_frames.owl#>\n",
    "                    PREFIX haidt: <https://w3id.org/spice/SON/HaidtValues#>\n",
    "\n",
    "                    CONSTRUCT { <'''+z+'''> vcvf:triggers ?o . }\n",
    "                    WHERE\n",
    "                      { <'''+z+'''> vcvf:triggers ?o . }\n",
    "                    '''\n",
    "                    )\n",
    "                    \n",
    "                    \n",
    "                    # store the triple in a graph\n",
    "                    \n",
    "                    valuesparql.setQuery(queryValueSubj)\n",
    "                    valuesparql.setReturnFormat(TURTLE)\n",
    "                    resultsValueSubj = valuesparql.query().convert()\n",
    "                    g_valueSubj = g_valueSubj.parse(resultsValueSubj, format=\"ttl\")\n",
    "                    \n",
    "                    \n",
    "\n",
    "            if k in o:\n",
    "                vo_list = []\n",
    "                vo_list.append(o)\n",
    "                for q in vo_list:\n",
    "                    \n",
    "                    # query to retrieve all objects of triples which trigger some value in ValueNet\n",
    "\n",
    "                    \n",
    "                    queryValueObj = (\n",
    "                    '''\n",
    "                    PREFIX vcvf: <http://www.semanticweb.org/sdg/ontologies/2022/0/valuecore_with_value_frames.owl#>\n",
    "                    PREFIX haidt: <https://w3id.org/spice/SON/HaidtValues#>\n",
    "\n",
    "                    CONSTRUCT { <'''+o+'''> vcvf:triggers ?o . }\n",
    "                    WHERE\n",
    "                    { <'''+o+'''> vcvf:triggers ?o . }\n",
    "                    '''\n",
    "                    )\n",
    "\n",
    "                    # store the triple in a graph\n",
    "                    \n",
    "                    valuesparql.setQuery(queryValueObj)\n",
    "                    valuesparql.setReturnFormat(TURTLE)\n",
    "                    resultsValueObj = valuesparql.query().convert()\n",
    "                    g_valueObj = g_valueObj.parse(resultsValueObj, format=\"ttl\")\n",
    "                    \n",
    "                    \n",
    "               \n",
    "                    \n",
    "        # merge all graphs in a new graph\n",
    "                \n",
    "        finalg = cell_graph + g_valueSubj + g_valueObj \n",
    "        \n",
    "\n",
    "        sub += [s for s,p,o in finalg if 'triggers' in p]\n",
    "        obj += [o for s,p,o in finalg if 'triggers' in p]\n",
    "        \n",
    "#  for s,p,o in finalg:\n",
    "#    print(s,p,o)\n",
    "\n",
    "  diz = {'sub':sub,\n",
    "         'obj':obj}  \n",
    "  return diz\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40334222-2481-4d67-b241-45dd048690cc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 483
    },
    "id": "40334222-2481-4d67-b241-45dd048690cc",
    "outputId": "3ce76964-16de-4da1-f14d-6dcf838cb439",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here\n",
      "Someone has to stop that awful killer.\n",
      "\n",
      "['harm']\n",
      "{'sent': ['Someone has to stop that awful killer.'], 'label': [nan], 'pred': ['harm'], 'trig': ['https://w3id.org/framester/wn/wn30/instances/synset-killer-noun-1, https://w3id.org/framester/data/framestercore/Killing']}\n",
      "0/1\n"
     ]
    }
   ],
   "source": [
    "from urllib.error import HTTPError\n",
    "\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "t = 20\n",
    "\n",
    "# here you declare the path to your file to be tested\n",
    "\n",
    "doc = pd.read_csv('test.csv')\n",
    "\n",
    "for index,row in doc.iterrows():\n",
    "  print(\"Here\")\n",
    "  txt = row['txt']\n",
    "  label = row['label']\n",
    "  try:\n",
    "    out1 = test_graph(txt)\n",
    "    print(txt)\n",
    "    print()\n",
    "    out2 = find_trigs('out1.ttl',txt)\n",
    "\n",
    "    # this is just to have a cleaner output without the full URI but only with the value name\n",
    "    \n",
    "    predizione = [ele.replace('https://w3id.org/spice/SON/HaidtValues#','').strip().lower() for ele in list(set([str(ele) for ele in out2['obj']]))]\n",
    "\n",
    "    print(predizione)\n",
    "\n",
    "    # in \"label\" you can put e.g. \"loyalty-betrayal\" from social chemistry file\n",
    "    \n",
    "    out = {'sent':[txt],\n",
    "        'label':[label],\n",
    "        'pred':[', '.join(predizione)],\n",
    "        'trig':[', '.join(list(set([str(ele) for ele in out2['sub']])))]}\n",
    "    print(out)\n",
    "\n",
    "    df = pd.DataFrame(out)\n",
    "    scrittura_file (df, '', 'emoval_test.csv', [k for k in out.keys()])\n",
    "    #if index==1:break\n",
    "\n",
    "    print(f\"{index}/{len(doc)}\")\n",
    "\n",
    "    if (requests.exceptions.HTTPError, requests.exceptions.ConnectionError, requests.exceptions.Timeout):\n",
    "      time.sleep(t)\n",
    "\n",
    "  except Exception:\n",
    "    print(\"ERRORE\")\n",
    "    continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6b4e2f59-ffa0-4c52-b454-9edb61ed64e8",
   "metadata": {
    "id": "6b4e2f59-ffa0-4c52-b454-9edb61ed64e8",
    "outputId": "93f4f491-a7c6-4fec-feed-8d94a450f8d8"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'float' object has no attribute 'split'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [11], line 24\u001b[0m\n\u001b[0;32m      9\u001b[0m doc \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124memoval_test.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     11\u001b[0m mapping \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     12\u001b[0m   \u001b[38;5;241m0\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcare\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     13\u001b[0m   \u001b[38;5;241m1\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpurity\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     21\u001b[0m   \u001b[38;5;241m9\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mharm\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     22\u001b[0m   \u001b[38;5;241m10\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauthority\u001b[39m\u001b[38;5;124m'\u001b[39m}\n\u001b[1;32m---> 24\u001b[0m label \u001b[38;5;241m=\u001b[39m  [[k \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m ele\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m k,v \u001b[38;5;129;01min\u001b[39;00m mapping\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m c\u001b[38;5;241m.\u001b[39mstrip() \u001b[38;5;241m==\u001b[39m v] \u001b[38;5;28;01mfor\u001b[39;00m ele \u001b[38;5;129;01min\u001b[39;00m doc[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[0;32m     25\u001b[0m predizioni \u001b[38;5;241m=\u001b[39m [[k \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(ele)\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m k,v \u001b[38;5;129;01min\u001b[39;00m mapping\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m c\u001b[38;5;241m.\u001b[39mstrip() \u001b[38;5;241m==\u001b[39m v] \u001b[38;5;28;01mfor\u001b[39;00m ele \u001b[38;5;129;01min\u001b[39;00m doc[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpred\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mone_hot\u001b[39m (etichette):\n",
      "Cell \u001b[1;32mIn [11], line 24\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      9\u001b[0m doc \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124memoval_test.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     11\u001b[0m mapping \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     12\u001b[0m   \u001b[38;5;241m0\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcare\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     13\u001b[0m   \u001b[38;5;241m1\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpurity\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     21\u001b[0m   \u001b[38;5;241m9\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mharm\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     22\u001b[0m   \u001b[38;5;241m10\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauthority\u001b[39m\u001b[38;5;124m'\u001b[39m}\n\u001b[1;32m---> 24\u001b[0m label \u001b[38;5;241m=\u001b[39m  [[k \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m \u001b[43mele\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m k,v \u001b[38;5;129;01min\u001b[39;00m mapping\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m c\u001b[38;5;241m.\u001b[39mstrip() \u001b[38;5;241m==\u001b[39m v] \u001b[38;5;28;01mfor\u001b[39;00m ele \u001b[38;5;129;01min\u001b[39;00m doc[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[0;32m     25\u001b[0m predizioni \u001b[38;5;241m=\u001b[39m [[k \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(ele)\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m k,v \u001b[38;5;129;01min\u001b[39;00m mapping\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m c\u001b[38;5;241m.\u001b[39mstrip() \u001b[38;5;241m==\u001b[39m v] \u001b[38;5;28;01mfor\u001b[39;00m ele \u001b[38;5;129;01min\u001b[39;00m doc[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpred\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mone_hot\u001b[39m (etichette):\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'float' object has no attribute 'split'"
     ]
    }
   ],
   "source": [
    "#metriche \n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn import metrics, model_selection, preprocessing\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "# this is eventually to test some metrics, to be fine tuned according to your needs\n",
    "\n",
    "doc = pd.read_csv('emoval_test.csv')\n",
    "\n",
    "mapping = {\n",
    "  0: 'care',\n",
    "  1: 'purity',\n",
    "  2: 'non-moral',\n",
    "  3: 'loyalty',\n",
    "  4: 'cheating',\n",
    "  5: 'fairness',\n",
    "  6: 'subversion',  \n",
    "  7: 'betrayal',\n",
    "  8: 'degradation',\n",
    "  9: 'harm',\n",
    "  10: 'authority'}\n",
    "\n",
    "label =  [[k for c in ele.split(',') for k,v in mapping.items() if c.strip() == v] for ele in doc['label']]\n",
    "predizioni = [[k for c in str(ele).split(',') for k,v in mapping.items() if c.strip() == v] for ele in doc['pred']]\n",
    "\n",
    "def one_hot (etichette):\n",
    "  out = []\n",
    "  for ele in etichette:\n",
    "    out_ = [0]*len(mapping)\n",
    "    for num in ele:\n",
    "      out_[num]=1\n",
    "    out+=[out_]\n",
    "  return out\n",
    "\n",
    "label = one_hot(label)\n",
    "predizioni = one_hot(predizioni)\n",
    "\n",
    "\n",
    "\n",
    "print(metrics.classification_report(label, predizioni, digits=2 , target_names = [v for v in mapping.values()]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cfdd53e-0dbc-49b8-9670-f5cd04677a72",
   "metadata": {
    "id": "2cfdd53e-0dbc-49b8-9670-f5cd04677a72"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
